{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Pandas",
   "id": "8b93bebbabbca04"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## keapa harus bealajar pandas ?\n",
    "\n",
    "pandas adalah jembatan untuk data mentah dan model ai.  Tanpa pandas kamu akan kesulitan untuk\n",
    "- membersikhkan data kotor ( 80 % waktu untuk AI engginer di habiskan disini )\n",
    "- mengubah format data agar bisa di baca algoritma\n",
    "- eksploarasi data untuk memahami pola\n",
    "- prepare data sebelum masuk ke Tensorflow/Pytorch/Scikit-Learn"
   ],
   "id": "ff4c67e6a8daadf5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# pandas di pakai untuk apa saja\n",
    "\n",
    "## 1. data loading ( baca file )\n",
    "\n",
    "panadas bisa hampir semua format :\n",
    "- CSV : data paling umum\n",
    "- excel : file .xlsx dari bisnis\n",
    "- JSON :  data dari api web\n",
    "- SQL Data base :  ambil data dari serevr\n",
    "- arquet : format efisien untuk big data\n",
    "\n",
    "Kpan dipakai ?\n",
    "-> setiap awal project! dara selal datang dalam bentuk file\n",
    "\n",
    "## 2. DATA CLEANING\n",
    "\n",
    "masalh yang di selesaikan\n",
    "- missing values (NaN ) -> Model akan error!\n",
    "- Duplikat data -> akan membuat model overfit\n",
    "- Tipe data salah - > angka tersimpans egbai text\n",
    "- outlier ekstem -> merusak akurasi mode\n",
    "\n",
    "contoh real :\n",
    "Data surver umur : *[25,27,Nan,150,30]*\n",
    "-> ada data kosong + ada yang salah (umur 150 )\n",
    "-> pandas dapat mendeteksi dan memperbaiki\n",
    "\n",
    "## 3.  FEATURE ENGGINERING ( BIKIN FITUR BARU  )\n",
    "\n",
    "ini yang bikin model jelek jadi bagus\n",
    "\n",
    "Machine Learning butuh fitur yang \"Berbicara \" ke mode :\n",
    "contoh kasus E-commerce :\n",
    "\n",
    "Data Mentah :\n",
    "- Tanggal pembelina : 2024-01-15\n",
    "- Harga : 500000\n",
    "\n",
    "Fitur baru yang lebih infromatif :\n",
    "- Hari dalam seminggu : senin ( orang belanja lebih banyak di weekend>)\n",
    "- Bulan : Januari ( ada pola musiman ? )\n",
    "- Jam : 14. 00 (Kapan peak hours )\n",
    "- Kategori harga : \"MAHAL\"  / \"MURAH\"\n",
    "\n",
    "**Pandas memudahkan:**\n",
    "\n",
    "- Ekstrak waktu dari tanggal\n",
    "- Gabungkan beberapa kolom\n",
    "- Buat kategori dari angka\n",
    "- Hitung rasio/presentase\n",
    "\n",
    "\n",
    "## 4. Data Transformation ( ubah format )\n",
    "\n",
    "masalah : Algoritma hanya mengerti angka\n",
    "X Model tidak bisa baca \"Jakarta\",\"LakiLaki\", \"Tinggi\"\n",
    "model butuh : [1,0,2] atau [[1,0,0] , [0,1,0],[0,0,1]]\n",
    "\n",
    "Teknik pandas :\n",
    "\n",
    "Teknik                  Kapan Dipakai                   Contoh\n",
    "\n",
    "One-Hot Encoding    Data kategori tanpa urutan          kota:Jakarta->[1,0,0], Bandung->[0,1,0]\n",
    "\n",
    "Label encoding      Data Kategori Tanpa urutan           Pendidikan : SD= 0, SMP=1,SMA=2\n",
    "\n",
    "scalling            Angka beda Skala Besar              Gaji(jutaan) vs umur (Puluhan)\n",
    "\n",
    "Binning             Bikin group dari angka              Umur->Muda/Tua\n",
    "\n",
    "\n",
    "## 5. Data Aggregation ( Ringkasa )\n",
    "\n",
    "Kegunaan :\n",
    "- melihat pola per group ( rata - rata gaji per departermen )\n",
    "- bikin fitur agregat ( total belanja user dalam 30 hari terakhir )\n",
    "- summary statisctic untuk EDA ( Exploratorry Data Analysis )\n",
    "\n",
    "-> smeua dihitung mengguanakn *groupby()*\n",
    "\n",
    "## 6. Data filtering ( saring data )\n",
    "\n",
    "kapan dipakai :\n",
    "- memisahkan training set vs test set\n",
    "- Buang outlier ekstrem\n",
    "- Ambil subset Data ( misalnya : hanya customer aktif )\n",
    "- Filter berdasarkan kondsii bisnis\n",
    "\n",
    "\n",
    "contoh\n",
    "\n",
    "studi kasuss : model prediksi harga rumah\n",
    "filter yang sering dipakai\n",
    "- harga rumah -> 100 juta ( Buang data karena tidak valid )\n",
    "- luas tanah   -> 100 m2 (fokus ke segment tertentu )\n",
    "- lokasi in['jakarta','bandung','surabaya']\n",
    "\n",
    "## 7. exploratory Data Analysis\n",
    "\n",
    "sebelum membuat sebuah model kita wajib tau :\n",
    "- apakah distribusi data normal atau skewed\n",
    "- korelasi antara variabel ( mana yang lebih penting )\n",
    "- ada pola tersembunyi?\n",
    "\n",
    "**Tools untuk pandas**\n",
    "- .describe()   -> statistik dasar\n",
    "- .corr() -> hubungan antar kolom\n",
    "- .calue_count()    -> frekuensi kategori\n",
    "- .groupby()    -> pola pergroup\n",
    "\n",
    "\n",
    "# workflow ai engginer dengan pandas\n",
    "\n",
    "1. Load Data ( read_csv, read_Excel)\n",
    "        |\n",
    "2. Check Quality ( isnull, duplicated, dytpes )\n",
    "        |\n",
    "3. Clean data ( fillna, drop_duplicates, astype)\n",
    "4. feature engginering ( create new columns, encoding)\n",
    "5. transform ( scaling, encoding categories )\n",
    "6. select feature ( correlation ), filter )\n",
    "7. export celan data - > masuk ke model ml/ dl"
   ],
   "id": "757490cd90f717fe"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# BAGIAN 1  :  DATA LOADING\n",
    "\n",
    "## tujuan : Belajar memabca data dari berbagai format file\n",
    "\n",
    "kapan dipakai :  setiap awal prokect ML/AI, dat aselalu dalam bentuk file\n",
    "\n",
    "file yang akan di baca\n",
    "- CSV ( paling umum )\n",
    "- Excel (.xlsx)\n",
    "- Json ( dari api )\n",
    "- SQL database\n",
    "- parquet ( big data )"
   ],
   "id": "3d7cbf4734cea465"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T08:43:45.414120Z",
     "start_time": "2025-11-19T08:43:44.553481Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"DATA LAODING DAN IMPORT\")\n",
    "print(\"=\" * 60)"
   ],
   "id": "c5810f266737e8c6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DATA LAODING DAN IMPORT\n",
      "============================================================\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T08:44:16.007722Z",
     "start_time": "2025-11-19T08:44:15.964472Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# BACA FILE CSV\n",
    "print(\"\\n [1] Membaca sv file \\n\")\n",
    "\n",
    "\"\"\"\n",
    "    CARA 1 : Basic ( default )\n",
    "    df = pd.read_csv('data.csv)\n",
    "\n",
    "    CARA 2 : dengan option ( Lebih Aman )\n",
    "    df = pd.read_csv('data.csv',\n",
    "                        sep=',',                -> pemisah kolom ( default = ,)\n",
    "                        encoing = 'utf-8',      -> encoding file\n",
    "                        na_values = ['NA', 'null', ''], -> nilai yang di anggap kosong\n",
    "                        parse_dates=['Tanggal'],    -> pemisah kolom tanggal otomatis di parse\n",
    "                        dytpes={'ID' : str})    -> oaksa tipe data tertentu\n",
    "    \"\"\"\n",
    "\n",
    "# SOMULASI KARENA TIDAK ADA FILE MAKA AKAN MEMBUAT DUMMY CSV\n",
    "\n",
    "print(\"Simulasi membaca csv :\")\n",
    "csv_data = \"\"\" Nama,Umur,Kota,Gaji\n",
    "Andi,24,Jakarta,50000000\n",
    "Budi,24,Jakarta,60000000\n",
    "Citra,,Surabaya,45000000\n",
    "Dewi,30,Jakarta,80000000\n",
    "\"\"\"\n",
    "\n",
    "# simpan ke file sementara ( dalam praktek nayta langsung read_csv\n",
    "with open('temp_data_.csv', 'w') as f:\n",
    "    f.write(csv_data)\n",
    "\n",
    "df_csv = pd.read_csv('temp_data_.csv')\n",
    "print(df_csv)\n",
    "print(f\"\\n Info : {df_csv.shape[0]}, baris, {df_csv.shape[1]} kolom\")"
   ],
   "id": "8b9635c7266a8e8a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " [1] Membaca sv file \n",
      "\n",
      "Simulasi membaca csv :\n",
      "    Nama  Umur      Kota      Gaji\n",
      "0   Andi  24.0   Jakarta  50000000\n",
      "1   Budi  24.0   Jakarta  60000000\n",
      "2  Citra   NaN  Surabaya  45000000\n",
      "3   Dewi  30.0   Jakarta  80000000\n",
      "\n",
      " Info : 4, baris, 4 kolom\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T08:51:04.378724Z",
     "start_time": "2025-11-19T08:51:04.349328Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# =========================================================\n",
    "#. Baca file dari EXCEL ( .xlsx )\n",
    "# =========================================================\n",
    "\n",
    "print(\"membaca file dari excel\")\n",
    "\n",
    "\"\"\"\n",
    "membutuhkan library tambahakn : pip install openpyxl\n",
    "cara 1 : baca sheet pertama\n",
    "df = pd.read_excel('data.xlsx')\n",
    "\n",
    "cara 2 : baca sheet tertentu\n",
    "df = pd.read_excel('data.xlsx', sheet_name='Sheet1')\n",
    "\n",
    "cara 3 : baca multiple sheet sekalioigus\n",
    "df = df.read_excel(data.xlsx, sheet_name='None')    -> semua sheet menjadi dict\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# simulasi : mmebuat dataframe dan pura pura jadi excel\n",
    "\n",
    "df_excel = pd.DataFrame({\n",
    "    'Produk' : ['laptop', 'Mouse', 'Keyboard'],\n",
    "    'Harga'   : [8000000,800000,1000000],\n",
    "    'Stock' : [21,555,212]\n",
    "})\n",
    "\n",
    "print(\"simulalsi data dari exel\")\n",
    "print(df_excel)"
   ],
   "id": "384686d49f12d7bc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "membaca file dari excel\n",
      "simulalsi data dari exel\n",
      "     Produk    Harga  Stock\n",
      "0    laptop  8000000     21\n",
      "1     Mouse   800000    555\n",
      "2  Keyboard  1000000    212\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## baca file json ( dari api web )",
   "id": "237725d2de9561b1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T09:16:00.761883Z",
     "start_time": "2025-11-19T09:16:00.732757Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "JSON biasa datang dari api web atau nosql database\n",
    "\n",
    "cara 1  : json berbentuk list of record\n",
    "\"\"\"\n",
    "json_data = '''\n",
    "[\n",
    "    {\"nama\" : \"Andi\", \"Umur\" : 25, \"Asal\" : \"Jakarta\"},\n",
    "    {\"nama\" : \"quincy\", \"Umur\" : 19, \"Asal\" : \"bradfort\"},\n",
    "    {\"nama\" : \"maverick\", \"Umur\" : 22, \"Asal\" : \"London\"}\n",
    "]\n",
    "'''\n",
    "\n",
    "# BACA DARI STRING ( dalam praktik : pd.read_json('data_json'))\n",
    "df_json = pd.read_json(json_data)\n",
    "print(\"Data dari JSON ( LIST OF RECORDDD : \")\n",
    "print(df_json)\n",
    "\n",
    "# CARA KE 2 JSON NESTED,  PERLU NORMALISASI\n",
    "\n",
    "json_nested = '''\n",
    "{\n",
    "\"data\" : [\n",
    "    {\"id\" : 1 , \"info\" : [{\"nama\" : \"quincy\", \"umur\" : 26}]},\n",
    "    {\"id\" : 2 , \"info\" : [{\"nama\" : \"max\", \"umur\" : 21}]}\n",
    "]\n",
    "}\n",
    "'''\n",
    "\n",
    "# untuk json nested perlu normalisasi\n",
    "import json\n",
    "nested = json.loads(json_nested)\n",
    "df_nested = pd.json_normalize(nested['data'],\n",
    "                              record_path=['info'], # masuk ke dalam list info untuk di pecah\n",
    "                              meta = ['id'] # teteap abwa kalom id dari luar list info\n",
    "                              )\n",
    "print(\"\\n data dari json nested : \")\n",
    "print(df_nested)"
   ],
   "id": "b35c30c080407962",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data dari JSON ( LIST OF RECORDDD : \n",
      "       nama  Umur      Asal\n",
      "0      Andi    25   Jakarta\n",
      "1    quincy    19  bradfort\n",
      "2  maverick    22    London\n",
      "\n",
      " data dari json nested : \n",
      "     nama  umur id\n",
      "0  quincy    26  1\n",
      "1     max    21  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\test\\Downloads\\mingw-w64-ucrt-x86_64-gcc-15.2.0-8-any.pkg\\ucrt64\\bin\\ipykernel_18552\\3179470553.py:15: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df_json = pd.read_json(json_data)\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# baca dari sql database\n",
   "id": "30d737a9433e9fe2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 4 BACA DARI SQL DATA BASE\n",
    "\n",
    "print(\"Membaca sql database with pandas\")\n",
    "\n",
    "\"\"\"\n",
    "    membutuhkan library : pip isntall sqlalchemy, pip install psycopg2\n",
    "\n",
    "    cara koneksi ke data base :\n",
    "    from sqlalchemy import create_engine\n",
    "\n",
    "    # Sqlite ( database lokal )\n",
    "    engine = = create_engine('sqlite://database.db')\n",
    "    df = pd.read_sql('SELECT * FROM table_name', engine ) -> engine jemabtann untuk menghubungkan python dengan databse\n",
    "\n",
    "    # postgreSQL\n",
    "    engine = create_engine('postgresql://user:password@localhost:5432/dbmame')\n",
    "    df = pd.read_sql('SELECT * FROM users Where ahe > 25', engine\n",
    "\n",
    "    #MySql\n",
    "    enine = create_engine('mysql+pymysql://user:passwprd@localhost/dbname')\n",
    "    df = pd.read_sql_tables('table_name', engine )\n",
    "    \"\"\"\n",
    "\n",
    "print(\"Contoh syntakx ( btuuh koneksi internet ) :\")\n",
    "print(\" df = pd.read_sql('SELECT * FROM users', engine)\")\n",
    "print(\" df = pd.read_sql('SELECT * WHERE age > 25', engine)\")\n"
   ],
   "id": "836985b43a0008aa"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 5. baca file paruet (Big data )\n",
   "id": "68f0d839c0ea85b3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(\"membaca parquet file (Big Data\")\n",
    "\n",
    "# parquet :  format kolom yang efisien, dipakai di big data ( spark,  AWS)\n",
    "# keuntungan : file kecil, baca lebih cepat , komptes itnggi\n",
    "\n",
    "# membtuhkan librarty : pip install pyarrow atau pip install fastparquet\n",
    "\n",
    "# cara [akai :\n",
    "# df = pd.read_parquet('data.parquet')\n",
    "#df = pd.read_parquet('data.parquet', engine = 'pyarrow')"
   ],
   "id": "bfab893ebf986a0a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# inspeksi data setelah loading",
   "id": "af719d95e165d888"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T10:15:51.015007Z",
     "start_time": "2025-11-19T10:15:50.963130Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"inspeksi data ( wajib dilakukan\")\n",
    "\n",
    "# gunakan df_csv sebgai contoh\n",
    "\n",
    "print(\"df.head() - lihat 5 baris pertama:\")\n",
    "print()\n",
    "print(df_csv.head())\n",
    "\n",
    "print()\n",
    "print()\n",
    "\n",
    "print(\"df.info() - lihat stukrutr data \")\n",
    "print()\n",
    "print(df_csv.info())\n",
    "\n",
    "print()\n",
    "print()\n",
    "\n",
    "print(\"df.shape() - ukuran data : \")\n",
    "print()\n",
    "print(f\"jumlah baris : {df_csv.shape[0]}, jumlah kolom : {df_csv.shape[1]}\")\n",
    "\n",
    "print()\n",
    "print()\n",
    "\n",
    "print(\"\\ndf.columns() - Nama kolom\")\n",
    "print()\n",
    "print(df_csv.columns.tolist())\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"df.dtypes() - tipe data di setiap kolom\")\n",
    "print()\n",
    "print(df_csv.dtypes)\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"\\n df.desribe() - statistik deskriptif\")\n",
    "print()\n",
    "print(df_csv.describe())"
   ],
   "id": "25b43fc812377713",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inspeksi data ( wajib dilakukan\n",
      "df.head() - lihat 5 baris pertama:\n",
      "\n",
      "    Nama  Umur      Kota      Gaji\n",
      "0   Andi  24.0   Jakarta  50000000\n",
      "1   Budi  24.0   Jakarta  60000000\n",
      "2  Citra   NaN  Surabaya  45000000\n",
      "3   Dewi  30.0   Jakarta  80000000\n",
      "\n",
      "\n",
      "df.info() - lihat stukrutr data \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4 entries, 0 to 3\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0    Nama   4 non-null      object \n",
      " 1   Umur    3 non-null      float64\n",
      " 2   Kota    4 non-null      object \n",
      " 3   Gaji    4 non-null      int64  \n",
      "dtypes: float64(1), int64(1), object(2)\n",
      "memory usage: 256.0+ bytes\n",
      "None\n",
      "\n",
      "\n",
      "df.shape() - ukuran data : \n",
      "\n",
      "jumlah baris : 4, jumlah kolom : 4\n",
      "\n",
      "\n",
      "\n",
      "df.columns() - Nama kolom\n",
      "\n",
      "[' Nama', 'Umur', 'Kota', 'Gaji']\n",
      "\n",
      "df.dtypes() - tipe data di setiap kolom\n",
      "\n",
      " Nama     object\n",
      "Umur     float64\n",
      "Kota      object\n",
      "Gaji       int64\n",
      "dtype: object\n",
      "\n",
      "\n",
      " df.desribe() - statistik deskriptif\n",
      "\n",
      "            Umur          Gaji\n",
      "count   3.000000  4.000000e+00\n",
      "mean   26.000000  5.875000e+07\n",
      "std     3.464102  1.547848e+07\n",
      "min    24.000000  4.500000e+07\n",
      "25%    24.000000  4.875000e+07\n",
      "50%    24.000000  5.500000e+07\n",
      "75%    27.000000  6.500000e+07\n",
      "max    30.000000  8.000000e+07\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# tips penting\n",
    "\n",
    "1. selalu cek *df.info()* setelah load - > pastikan tipe data benar\n",
    "2. untuk file besar (>500 mb ) pakai:\n",
    "        - chunksize = baca perb bagian\n",
    "            for chunk in pd.read_vsc('big.csv', chunksize=10000):\n",
    "                process(chunk)\n",
    "\n",
    "        - usecols : baca kolom tertentu saja\n",
    "        2. df = pd.read_csv('data.csv', usecols=['nama','gaji'])\n",
    "\n",
    "3. kalau error encoding coba :\n",
    "df = pd.read_csv('data.csv' , encoding='latin-1')\n",
    "    ataui encoding='cp1252'\n",
    "\n",
    "4. untuk tanggal, selalu parse :\n",
    "df = pd.read_csb('data.csv', parse_datas=['tanggal'"
   ],
   "id": "7346fd4fb6366cc4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
