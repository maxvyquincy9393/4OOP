{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ MACHINE LEARNING OPTIMIZER - TUTORIAL SUPER LENGKAP\n",
    "\n",
    "**Tujuan**: Menjadi AI Engineer Profesional dengan memahami SETIAP DETAIL!\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Daftar Isi:\n",
    "1. **Penjelasan Fungsi NumPy & Pandas**\n",
    "2. **Matematika & Rumus Linear Regression**\n",
    "3. **Optimizer Algorithms (GD, Momentum, Adam)**\n",
    "4. **Training & Evaluation**\n",
    "5. **Visualisasi & Analisis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# PART 1: IMPORT & PENJELASAN SETIAP LIBRARY\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NUMPY - Library untuk operasi matematika & array\n",
    "import numpy as np\n",
    "\n",
    "# PANDAS - Library untuk manipulasi data (seperti Excel di Python)\n",
    "import pandas as pd\n",
    "\n",
    "# MATPLOTLIB - Library untuk visualisasi (membuat grafik)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# SEABORN - Library visualisasi yang lebih cantik\n",
    "import seaborn as sns\n",
    "\n",
    "# SKLEARN - Library machine learning (sudah jadi)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "import time\n",
    "\n",
    "# Setting agar plot muncul langsung di notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# Setting style visualisasi\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úÖ Semua library berhasil di-import!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# PART 2: PENJELASAN FUNGSI-FUNGSI NUMPY\n",
    "---\n",
    "\n",
    "## üîç FUNGSI NUMPY YANG AKAN KITA PAKAI:\n",
    "\n",
    "### 1. **np.zeros()**\n",
    "**Fungsi**: Membuat array yang isinya semua NOL\n",
    "\n",
    "**Cara Pakai**:\n",
    "```python\n",
    "np.zeros((3, 1))  # Buat array 3 baris, 1 kolom, isi semua 0\n",
    "```\n",
    "\n",
    "**Analogi**: Seperti bikin kertas kosong dengan ukuran tertentu\n",
    "\n",
    "**Kenapa dipakai?**: Untuk inisialisasi weights (bobot) di awal training. Kita mulai dari 0, lalu perlahan diupdate.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **.shape**\n",
    "**Fungsi**: Melihat ukuran/dimensi array\n",
    "\n",
    "**Cara Pakai**:\n",
    "```python\n",
    "X.shape  # Output: (100, 5) artinya 100 baris, 5 kolom\n",
    "```\n",
    "\n",
    "**Analogi**: Seperti ngecek ukuran meja (panjang x lebar)\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **np.dot()** atau **.dot()**\n",
    "**Fungsi**: Perkalian matrix (matrix multiplication)\n",
    "\n",
    "**Cara Pakai**:\n",
    "```python\n",
    "np.dot(X, w)  # atau X.dot(w)\n",
    "```\n",
    "\n",
    "**Rumus Matematika**:\n",
    "```\n",
    "Jika X = [[1, 2],    w = [[5],\n",
    "          [3, 4]]          [6]]\n",
    "\n",
    "Hasil = [[1*5 + 2*6],  = [[17],\n",
    "         [3*5 + 4*6]]     [39]]\n",
    "```\n",
    "\n",
    "**Analogi**: Seperti menghitung total belanja. Kamu punya 2 apel (harga 5rb) dan 3 jeruk (harga 6rb). Total = 2√ó5 + 3√ó6 = 28rb\n",
    "\n",
    "---\n",
    "\n",
    "### 4. **np.mean()**\n",
    "**Fungsi**: Menghitung rata-rata\n",
    "\n",
    "**Rumus**: mean = (x‚ÇÅ + x‚ÇÇ + ... + x‚Çô) / n\n",
    "\n",
    "**Analogi**: Nilai rata-rata ujian kamu\n",
    "\n",
    "---\n",
    "\n",
    "### 5. **np.sqrt()**\n",
    "**Fungsi**: Akar kuadrat\n",
    "\n",
    "**Rumus**: ‚àöx\n",
    "\n",
    "**Contoh**: np.sqrt(16) = 4\n",
    "\n",
    "---\n",
    "\n",
    "### 6. **.T** (Transpose)\n",
    "**Fungsi**: Membalik baris jadi kolom, kolom jadi baris\n",
    "\n",
    "**Contoh**:\n",
    "```\n",
    "X = [[1, 2, 3],     X.T = [[1, 4],\n",
    "     [4, 5, 6]]            [2, 5],\n",
    "                           [3, 6]]\n",
    "```\n",
    "\n",
    "**Analogi**: Seperti memutar kertas 90 derajat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEMO FUNGSI NUMPY\n",
    "print(\"=\" * 60)\n",
    "print(\"DEMO: Fungsi-fungsi NumPy\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1. np.zeros()\n",
    "print(\"\\n1. np.zeros() - Membuat array berisi NOL\")\n",
    "zeros_array = np.zeros((3, 2))\n",
    "print(f\"Shape: {zeros_array.shape}\")\n",
    "print(zeros_array)\n",
    "\n",
    "# 2. .shape\n",
    "print(\"\\n2. .shape - Melihat ukuran array\")\n",
    "X_demo = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "print(f\"X_demo.shape = {X_demo.shape}  # (2 baris, 3 kolom)\")\n",
    "\n",
    "# 3. np.dot() - Matrix multiplication\n",
    "print(\"\\n3. np.dot() - Perkalian Matrix\")\n",
    "A = np.array([[1, 2], [3, 4]])\n",
    "B = np.array([[5], [6]])\n",
    "result = np.dot(A, B)\n",
    "print(f\"A = \\n{A}\")\n",
    "print(f\"B = \\n{B}\")\n",
    "print(f\"A.dot(B) = \\n{result}\")\n",
    "print(\"Perhitungan: [1*5 + 2*6] = [17], [3*5 + 4*6] = [39]\")\n",
    "\n",
    "# 4. np.mean()\n",
    "print(\"\\n4. np.mean() - Rata-rata\")\n",
    "data = np.array([10, 20, 30, 40, 50])\n",
    "print(f\"Data: {data}\")\n",
    "print(f\"Mean: {np.mean(data)}  # (10+20+30+40+50)/5 = 30\")\n",
    "\n",
    "# 5. np.sqrt()\n",
    "print(\"\\n5. np.sqrt() - Akar kuadrat\")\n",
    "print(f\"‚àö16 = {np.sqrt(16)}\")\n",
    "print(f\"‚àö25 = {np.sqrt(25)}\")\n",
    "\n",
    "# 6. .T - Transpose\n",
    "print(\"\\n6. .T - Transpose (balik baris-kolom)\")\n",
    "X = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "print(f\"X = \\n{X}\")\n",
    "print(f\"X.T = \\n{X.T}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# PART 3: LOAD DATA & PREPROCESSING\n",
    "---\n",
    "\n",
    "## üìä PENJELASAN PANDAS FUNCTIONS:\n",
    "\n",
    "### **pd.read_csv()**\n",
    "- **Fungsi**: Membaca file CSV (Comma Separated Values)\n",
    "- **Analogi**: Seperti buka file Excel\n",
    "\n",
    "### **df.drop()**\n",
    "- **Fungsi**: Menghapus kolom atau baris\n",
    "- **Parameter**:\n",
    "  - `axis=1`: hapus kolom\n",
    "  - `axis=0`: hapus baris\n",
    "  - `inplace=True`: langsung ubah df asli\n",
    "\n",
    "### **df.shape**\n",
    "- **Fungsi**: Melihat ukuran dataframe (baris, kolom)\n",
    "\n",
    "### **pd.get_dummies()**\n",
    "- **Fungsi**: One-hot encoding (ubah kategori jadi angka)\n",
    "- **Contoh**:\n",
    "  ```\n",
    "  Warna: [Merah, Biru, Merah]\n",
    "  \n",
    "  Jadi:\n",
    "  Warna_Biru  Warna_Merah\n",
    "      0            1\n",
    "      1            0\n",
    "      0            1\n",
    "  ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"LOADING DATA\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Baca file CSV\n",
    "df = pd.read_csv(\"dataset/CarPrice_Assignment.csv\")\n",
    "\n",
    "print(f\"\\nüìä Dataset shape: {df.shape}\")\n",
    "print(f\"   Artinya: {df.shape[0]} mobil, {df.shape[1]} kolom/fitur\")\n",
    "\n",
    "# Lihat 5 baris pertama\n",
    "print(\"\\n5 Baris Pertama:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Info tentang dataset\n",
    "print(\"\\nInfo Dataset:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hapus kolom car_ID (tidak relevan untuk prediksi)\n",
    "df.drop(\"car_ID\", axis=1, inplace=True)\n",
    "print(f\"‚úÖ Kolom 'car_ID' dihapus\")\n",
    "print(f\"Shape sekarang: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ PISAHKAN TARGET (y) DAN FEATURES (X)\n",
    "\n",
    "**Target (y)**: Yang mau kita prediksi (harga mobil)\n",
    "\n",
    "**Features (X)**: Data yang kita pakai untuk prediksi (merek, tahun, dll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pisahkan y (target) dan X (features)\n",
    "y = df[\"price\"].values.reshape(-1, 1).astype(np.float64)\n",
    "X = df.drop(\"price\", axis=1)\n",
    "\n",
    "print(\"Target (y) - Harga Mobil:\")\n",
    "print(f\"  Shape: {y.shape}  # {y.shape[0]} mobil\")\n",
    "print(f\"  Mean:  ${np.mean(y):,.2f}\")\n",
    "print(f\"  Min:   ${np.min(y):,.2f}\")\n",
    "print(f\"  Max:   ${np.max(y):,.2f}\")\n",
    "\n",
    "print(f\"\\nFeatures (X):\")\n",
    "print(f\"  Shape: {X.shape}  # {X.shape[1]} fitur\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üî¢ ONE-HOT ENCODING\n",
    "\n",
    "**Masalah**: Komputer tidak bisa baca teks (\"Toyota\", \"Honda\")\n",
    "\n",
    "**Solusi**: Ubah jadi angka 0 dan 1\n",
    "\n",
    "**Contoh**:\n",
    "```\n",
    "Brand: [Toyota, Honda, Toyota]\n",
    "\n",
    "Jadi:\n",
    "Brand_Honda  Brand_Toyota\n",
    "    0            1\n",
    "    1            0\n",
    "    0            1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding\n",
    "print(\"Sebelum encoding:\")\n",
    "print(f\"Jumlah kolom: {X.shape[1]}\")\n",
    "\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "print(f\"\\nSetelah encoding:\")\n",
    "print(f\"Jumlah kolom: {X.shape[1]}\")\n",
    "print(f\"\\nKolom bertambah karena setiap kategori jadi kolom sendiri!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìè STANDARDIZATION (SCALING)\n",
    "\n",
    "**Masalah**: Fitur punya skala berbeda\n",
    "- Tahun: 1990-2020 (skala puluhan)\n",
    "- Harga: 5000-50000 (skala ribuan)\n",
    "\n",
    "**Solusi**: Standardisasi ke skala yang sama\n",
    "\n",
    "**Rumus**:\n",
    "```\n",
    "z = (x - Œº) / œÉ\n",
    "\n",
    "Dimana:\n",
    "- x = nilai asli\n",
    "- Œº (mu) = mean (rata-rata)\n",
    "- œÉ (sigma) = standard deviation\n",
    "```\n",
    "\n",
    "**Hasil**: Semua fitur punya mean=0, std=1\n",
    "\n",
    "**Analogi**: Seperti mengubah semua nilai ujian ke skala 0-100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardization\n",
    "num_cols = X.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
    "scaler = StandardScaler()\n",
    "\n",
    "print(\"Sebelum standardisasi:\")\n",
    "print(X[num_cols].describe())\n",
    "\n",
    "X[num_cols] = scaler.fit_transform(X[num_cols])\n",
    "\n",
    "print(\"\\nSetelah standardisasi:\")\n",
    "print(X[num_cols].describe())\n",
    "print(\"\\n‚úÖ Perhatikan: mean ‚âà 0, std ‚âà 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert ke numpy array\n",
    "X = X.values.astype(np.float64)\n",
    "\n",
    "print(f\"Final X shape: {X.shape}\")\n",
    "print(f\"Final y shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÇÔ∏è TRAIN/TEST SPLIT\n",
    "\n",
    "**Kenapa split?**\n",
    "- **Training set**: Untuk belajar (80%)\n",
    "- **Test set**: Untuk ujian (20%)\n",
    "\n",
    "**Analogi**: Seperti belajar dari buku latihan, lalu ujian pakai soal baru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Data Split:\")\n",
    "print(f\"  Training: {X_train.shape[0]} mobil (80%)\")\n",
    "print(f\"  Testing:  {X_test.shape[0]} mobil (20%)\")\n",
    "print(f\"\\n‚úÖ Data siap untuk training!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# PART 4: MATEMATIKA LINEAR REGRESSION\n",
    "---\n",
    "\n",
    "## üìê RUMUS DASAR LINEAR REGRESSION\n",
    "\n",
    "### **Persamaan Prediksi**:\n",
    "```\n",
    "≈∑ = w‚ÇÅx‚ÇÅ + w‚ÇÇx‚ÇÇ + ... + w‚Çôx‚Çô + b\n",
    "\n",
    "Atau dalam bentuk matrix:\n",
    "≈∑ = Xw + b\n",
    "```\n",
    "\n",
    "**Dimana**:\n",
    "- `≈∑` (y-hat) = prediksi\n",
    "- `X` = features (data input)\n",
    "- `w` = weights (bobot)\n",
    "- `b` = bias (intercept)\n",
    "\n",
    "**Analogi**: \n",
    "```\n",
    "Harga Rumah = (Luas √ó w‚ÇÅ) + (Kamar √ó w‚ÇÇ) + (Lokasi √ó w‚ÇÉ) + b\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üìä LOSS FUNCTION (MSE)\n",
    "\n",
    "**Mean Squared Error**:\n",
    "```\n",
    "MSE = (1/n) Œ£(≈∑·µ¢ - y·µ¢)¬≤\n",
    "```\n",
    "\n",
    "**Cara Baca**:\n",
    "1. `(≈∑·µ¢ - y·µ¢)` = error (selisih prediksi vs actual)\n",
    "2. `¬≤` = dikuadratkan (agar error negatif jadi positif)\n",
    "3. `Œ£` (sigma) = jumlahkan semua\n",
    "4. `(1/n)` = rata-ratakan\n",
    "\n",
    "**Analogi**: Seperti ngitung rata-rata kesalahan tebakan kamu\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ GRADIENT (TURUNAN)\n",
    "\n",
    "**Gradient untuk w**:\n",
    "```\n",
    "‚àÇL/‚àÇw = (2/n) X·µÄ(≈∑ - y)\n",
    "```\n",
    "\n",
    "**Gradient untuk b**:\n",
    "```\n",
    "‚àÇL/‚àÇb = (2/n) Œ£(≈∑ - y)\n",
    "```\n",
    "\n",
    "**Cara Baca**:\n",
    "- `‚àÇL/‚àÇw` = \"turunan Loss terhadap w\"\n",
    "- Memberitahu: \"Ke arah mana w harus diubah untuk mengurangi error\"\n",
    "\n",
    "**Analogi**: Seperti kompas yang nunjukin arah turun gunung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNGSI INTI\n",
    "\n",
    "def predict(X, w, b):\n",
    "    \"\"\"\n",
    "    Prediksi: ≈∑ = Xw + b\n",
    "    \n",
    "    Args:\n",
    "        X: features (n_samples, n_features)\n",
    "        w: weights (n_features, 1)\n",
    "        b: bias (scalar)\n",
    "    \n",
    "    Returns:\n",
    "        predictions (n_samples, 1)\n",
    "    \"\"\"\n",
    "    return np.dot(X, w) + b\n",
    "\n",
    "\n",
    "def mse(y_pred, y):\n",
    "    \"\"\"\n",
    "    Mean Squared Error: MSE = (1/n) Œ£(≈∑·µ¢ - y·µ¢)¬≤\n",
    "    \n",
    "    Args:\n",
    "        y_pred: prediksi\n",
    "        y: nilai sebenarnya\n",
    "    \n",
    "    Returns:\n",
    "        MSE (scalar)\n",
    "    \"\"\"\n",
    "    return np.mean((y_pred - y) ** 2)\n",
    "\n",
    "\n",
    "def compute_gradients(X, y, y_pred):\n",
    "    \"\"\"\n",
    "    Hitung gradients:\n",
    "    - dw = (2/n) X·µÄ(≈∑ - y)\n",
    "    - db = (2/n) Œ£(≈∑ - y)\n",
    "    \n",
    "    Args:\n",
    "        X: features\n",
    "        y: target\n",
    "        y_pred: prediksi\n",
    "    \n",
    "    Returns:\n",
    "        dw, db (gradients)\n",
    "    \"\"\"\n",
    "    n = len(y)\n",
    "    dw = (2.0/n) * np.dot(X.T, (y_pred - y))\n",
    "    db = (2.0/n) * np.sum(y_pred - y)\n",
    "    return dw, db\n",
    "\n",
    "print(\"‚úÖ Fungsi inti sudah didefinisikan!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# PART 5: OPTIMIZER ALGORITHMS\n",
    "---\n",
    "\n",
    "## 1Ô∏è‚É£ GRADIENT DESCENT (GD)\n",
    "\n",
    "**Rumus Update**:\n",
    "```\n",
    "w = w - Œ± √ó ‚àÇL/‚àÇw\n",
    "b = b - Œ± √ó ‚àÇL/‚àÇb\n",
    "```\n",
    "\n",
    "**Dimana**:\n",
    "- `Œ±` (alpha) = learning rate (seberapa besar langkah)\n",
    "- `‚àÇL/‚àÇw` = gradient (arah turun)\n",
    "\n",
    "**Cara Kerja**:\n",
    "1. Hitung prediksi\n",
    "2. Hitung error (loss)\n",
    "3. Hitung gradient (arah turun)\n",
    "4. Update parameter (turun sedikit)\n",
    "5. Ulangi!\n",
    "\n",
    "**Analogi**: Turun gunung dengan mata tertutup. Kamu cek kemiringan tanah, lalu melangkah ke arah yang lebih rendah."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gradient_descent(X, y, lr=0.01, epochs=150, verbose=True):\n",
    "    \"\"\"\n",
    "    Gradient Descent Optimizer\n",
    "    \n",
    "    Args:\n",
    "        X: training features\n",
    "        y: training targets\n",
    "        lr: learning rate (Œ±)\n",
    "        epochs: jumlah iterasi\n",
    "        verbose: print progress atau tidak\n",
    "    \n",
    "    Returns:\n",
    "        w, b, losses, training_time\n",
    "    \"\"\"\n",
    "    # Inisialisasi parameters\n",
    "    n_features = X.shape[1]\n",
    "    w = np.zeros((n_features, 1), dtype=np.float64)  # Mulai dari 0\n",
    "    b = 0.0\n",
    "    \n",
    "    losses = []\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # 1. Forward pass (prediksi)\n",
    "        y_pred = predict(X, w, b)\n",
    "        \n",
    "        # 2. Compute loss\n",
    "        loss = mse(y_pred, y)\n",
    "        losses.append(loss)\n",
    "        \n",
    "        # 3. Compute gradients\n",
    "        dw, db = compute_gradients(X, y, y_pred)\n",
    "        \n",
    "        # 4. Update parameters\n",
    "        w = w - lr * dw  # w_new = w_old - Œ± √ó gradient\n",
    "        b = b - lr * db\n",
    "        \n",
    "        # Print progress\n",
    "        if verbose and epoch % 30 == 0:\n",
    "            print(f\"Epoch {epoch:3d} | Loss: {loss:,.2f}\")\n",
    "    \n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"\\n‚úÖ Training selesai dalam {training_time:.2f} detik\")\n",
    "    \n",
    "    return w, b, losses, training_time\n",
    "\n",
    "print(\"‚úÖ Gradient Descent function ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ MOMENTUM\n",
    "\n",
    "**Rumus**:\n",
    "```\n",
    "v = Œ≤ √ó v + Œ± √ó ‚àÇL/‚àÇw    (velocity update)\n",
    "w = w - v                 (parameter update)\n",
    "```\n",
    "\n",
    "**Dimana**:\n",
    "- `v` = velocity (kecepatan)\n",
    "- `Œ≤` (beta) = momentum coefficient (biasanya 0.9)\n",
    "\n",
    "**Cara Kerja**:\n",
    "- Mengakumulasi gradient dari iterasi sebelumnya\n",
    "- Seperti bola menggelinding: semakin lama semakin cepat\n",
    "\n",
    "**Analogi**: \n",
    "- GD = jalan kaki turun gunung\n",
    "- Momentum = naik sepeda turun gunung (punya momentum!)\n",
    "\n",
    "**Keuntungan**:\n",
    "- Lebih cepat konvergen\n",
    "- Bisa melewati local minima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_momentum(X, y, lr=0.01, epochs=150, beta=0.9, verbose=True):\n",
    "    \"\"\"\n",
    "    Momentum Optimizer\n",
    "    \n",
    "    Args:\n",
    "        beta: momentum coefficient (0.9 recommended)\n",
    "    \"\"\"\n",
    "    n_features = X.shape[1]\n",
    "    w = np.zeros((n_features, 1), dtype=np.float64)\n",
    "    b = 0.0\n",
    "    \n",
    "    # Inisialisasi velocity\n",
    "    vw = np.zeros((n_features, 1), dtype=np.float64)\n",
    "    vb = 0.0\n",
    "    \n",
    "    losses = []\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Forward pass\n",
    "        y_pred = predict(X, w, b)\n",
    "        loss = mse(y_pred, y)\n",
    "        losses.append(loss)\n",
    "        \n",
    "        # Compute gradients\n",
    "        dw, db = compute_gradients(X, y, y_pred)\n",
    "        \n",
    "        # Update velocity: v = Œ≤√óv + Œ±√ógradient\n",
    "        vw = beta * vw + lr * dw\n",
    "        vb = beta * vb + lr * db\n",
    "        \n",
    "        # Update parameters: w = w - v\n",
    "        w = w - vw\n",
    "        b = b - vb\n",
    "        \n",
    "        if verbose and epoch % 30 == 0:\n",
    "            print(f\"Epoch {epoch:3d} | Loss: {loss:,.2f}\")\n",
    "    \n",
    "    training_time = time.time() - start_time\n",
    "    if verbose:\n",
    "        print(f\"\\n‚úÖ Training selesai dalam {training_time:.2f} detik\")\n",
    "    \n",
    "    return w, b, losses, training_time\n",
    "\n",
    "print(\"‚úÖ Momentum function ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ ADAM (Adaptive Moment Estimation)\n",
    "\n",
    "**Rumus Lengkap**:\n",
    "```\n",
    "m = Œ≤‚ÇÅ √ó m + (1-Œ≤‚ÇÅ) √ó ‚àÇL/‚àÇw      (first moment - mean)\n",
    "v = Œ≤‚ÇÇ √ó v + (1-Œ≤‚ÇÇ) √ó (‚àÇL/‚àÇw)¬≤   (second moment - variance)\n",
    "\n",
    "mÃÇ = m / (1 - Œ≤‚ÇÅ·µó)                (bias correction)\n",
    "vÃÇ = v / (1 - Œ≤‚ÇÇ·µó)                (bias correction)\n",
    "\n",
    "w = w - Œ± √ó mÃÇ / (‚àövÃÇ + Œµ)        (update)\n",
    "```\n",
    "\n",
    "**Dimana**:\n",
    "- `m` = first moment (rata-rata gradient)\n",
    "- `v` = second moment (variance gradient)\n",
    "- `Œ≤‚ÇÅ` = 0.9 (decay rate untuk m)\n",
    "- `Œ≤‚ÇÇ` = 0.999 (decay rate untuk v)\n",
    "- `Œµ` = 1e-8 (untuk numerical stability)\n",
    "- `t` = timestep (epoch ke berapa)\n",
    "\n",
    "**Cara Kerja**:\n",
    "1. Track rata-rata gradient (m)\n",
    "2. Track variance gradient (v)\n",
    "3. Adaptive learning rate untuk setiap parameter\n",
    "4. Bias correction di awal training\n",
    "\n",
    "**Analogi**: \n",
    "- Seperti GPS yang pintar\n",
    "- Tahu kapan harus jalan cepat, kapan harus pelan\n",
    "- Setiap parameter punya \"kecepatan\" sendiri\n",
    "\n",
    "**Kenapa PALING POPULER?**\n",
    "- Kombinasi Momentum + RMSProp\n",
    "- Adaptive learning rate\n",
    "- Reliable untuk berbagai masalah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_adam(X, y, lr=0.01, epochs=150, b1=0.9, b2=0.999, eps=1e-8, verbose=True):\n",
    "    \"\"\"\n",
    "    Adam Optimizer\n",
    "    \n",
    "    Args:\n",
    "        b1: beta1 untuk first moment (0.9)\n",
    "        b2: beta2 untuk second moment (0.999)\n",
    "        eps: epsilon untuk numerical stability (1e-8)\n",
    "    \"\"\"\n",
    "    n_features = X.shape[1]\n",
    "    w = np.zeros((n_features, 1), dtype=np.float64)\n",
    "    b = 0.0\n",
    "    \n",
    "    # Inisialisasi moments\n",
    "    m_w = np.zeros((n_features, 1), dtype=np.float64)  # first moment untuk w\n",
    "    v_w = np.zeros((n_features, 1), dtype=np.float64)  # second moment untuk w\n",
    "    m_b = 0.0  # first moment untuk b\n",
    "    v_b = 0.0  # second moment untuk b\n",
    "    \n",
    "    losses = []\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for epoch in range(1, epochs + 1):  # Mulai dari 1 untuk bias correction\n",
    "        # Forward pass\n",
    "        y_pred = predict(X, w, b)\n",
    "        loss = mse(y_pred, y)\n",
    "        losses.append(loss)\n",
    "        \n",
    "        # Compute gradients\n",
    "        dw, db = compute_gradients(X, y, y_pred)\n",
    "        \n",
    "        # Update first moment: m = Œ≤‚ÇÅ√óm + (1-Œ≤‚ÇÅ)√ógradient\n",
    "        m_w = b1 * m_w + (1 - b1) * dw\n",
    "        m_b = b1 * m_b + (1 - b1) * db\n",
    "        \n",
    "        # Update second moment: v = Œ≤‚ÇÇ√óv + (1-Œ≤‚ÇÇ)√ógradient¬≤\n",
    "        v_w = b2 * v_w + (1 - b2) * (dw ** 2)\n",
    "        v_b = b2 * v_b + (1 - b2) * (db ** 2)\n",
    "        \n",
    "        # Bias correction\n",
    "        m_w_hat = m_w / (1 - b1 ** epoch)\n",
    "        m_b_hat = m_b / (1 - b1 ** epoch)\n",
    "        v_w_hat = v_w / (1 - b2 ** epoch)\n",
    "        v_b_hat = v_b / (1 - b2 ** epoch)\n",
    "        \n",
    "        # Update parameters: w = w - Œ± √ó mÃÇ / (‚àövÃÇ + Œµ)\n",
    "        w = w - lr * m_w_hat / (np.sqrt(v_w_hat) + eps)\n",
    "        b = b - lr * m_b_hat / (np.sqrt(v_b_hat) + eps)\n",
    "        \n",
    "        if verbose and (epoch - 1) % 30 == 0:\n",
    "            print(f\"Epoch {epoch-1:3d} | Loss: {loss:,.2f}\")\n",
    "    \n",
    "    training_time = time.time() - start_time\n",
    "    if verbose:\n",
    "        print(f\"\\n‚úÖ Training selesai dalam {training_time:.2f} detik\")\n",
    "    \n",
    "    return w, b, losses, training_time\n",
    "\n",
    "print(\"‚úÖ Adam function ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# PART 6: TRAINING SEMUA OPTIMIZER\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"TRAINING DIMULAI!\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "optimizers = {}\n",
    "\n",
    "# 1. Gradient Descent\n",
    "print(\"\\n1Ô∏è‚É£ GRADIENT DESCENT\")\n",
    "print(\"-\" * 70)\n",
    "w, b, losses, train_time = train_gradient_descent(X_train, y_train, lr=0.01, epochs=150)\n",
    "optimizers[\"GD\"] = (w, b, losses, train_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Momentum\n",
    "print(\"\\n2Ô∏è‚É£ MOMENTUM\")\n",
    "print(\"-\" * 70)\n",
    "w, b, losses, train_time = train_momentum(X_train, y_train, lr=0.01, epochs=150, beta=0.9)\n",
    "optimizers[\"Momentum\"] = (w, b, losses, train_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Adam\n",
    "print(\"\\n3Ô∏è‚É£ ADAM\")\n",
    "print(\"-\" * 70)\n",
    "w, b, losses, train_time = train_adam(X_train, y_train, lr=0.01, epochs=150)\n",
    "optimizers[\"Adam\"] = (w, b, losses, train_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# PART 7: EVALUATION\n",
    "---\n",
    "\n",
    "## üìä METRICS YANG DIPAKAI:\n",
    "\n",
    "### 1. **MSE (Mean Squared Error)**\n",
    "```\n",
    "MSE = (1/n) Œ£(≈∑·µ¢ - y·µ¢)¬≤\n",
    "```\n",
    "- Rata-rata kuadrat error\n",
    "- Semakin kecil semakin bagus\n",
    "\n",
    "### 2. **RMSE (Root Mean Squared Error)**\n",
    "```\n",
    "RMSE = ‚àöMSE\n",
    "```\n",
    "- Akar dari MSE\n",
    "- Dalam satuan yang sama dengan y (dollar)\n",
    "- Lebih mudah diinterpretasi\n",
    "\n",
    "### 3. **MAE (Mean Absolute Error)**\n",
    "```\n",
    "MAE = (1/n) Œ£|≈∑·µ¢ - y·µ¢|\n",
    "```\n",
    "- Rata-rata absolute error\n",
    "- Tidak dikuadratkan\n",
    "\n",
    "### 4. **R¬≤ Score (Coefficient of Determination)**\n",
    "```\n",
    "R¬≤ = 1 - (SS_res / SS_tot)\n",
    "\n",
    "Dimana:\n",
    "SS_res = Œ£(y·µ¢ - ≈∑·µ¢)¬≤  (residual sum of squares)\n",
    "SS_tot = Œ£(y·µ¢ - »≥)¬≤   (total sum of squares)\n",
    "```\n",
    "\n",
    "**Interpretasi R¬≤**:\n",
    "- R¬≤ = 1.0 ‚Üí Perfect prediction (100%)\n",
    "- R¬≤ = 0.8 ‚Üí Model menjelaskan 80% variance\n",
    "- R¬≤ = 0.0 ‚Üí Model tidak lebih baik dari rata-rata\n",
    "- R¬≤ < 0.0 ‚Üí Model lebih buruk dari rata-rata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"EVALUATION ON TEST SET\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, (w, b, losses, train_time) in optimizers.items():\n",
    "    # Prediksi di test set\n",
    "    y_pred_test = predict(X_test, w, b)\n",
    "    \n",
    "    # Hitung metrics\n",
    "    test_mse = mean_squared_error(y_test, y_pred_test)\n",
    "    test_rmse = np.sqrt(test_mse)\n",
    "    test_mae = mean_absolute_error(y_test, y_pred_test)\n",
    "    r2 = r2_score(y_test, y_pred_test)\n",
    "    \n",
    "    results.append({\n",
    "        'Optimizer': name,\n",
    "        'Train Loss': losses[-1],\n",
    "        'Test RMSE': test_rmse,\n",
    "        'Test MAE': test_mae,\n",
    "        'R¬≤ Score': r2,\n",
    "        'Time (s)': train_time\n",
    "    })\n",
    "    \n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  R¬≤ Score:  {r2:.4f}\")\n",
    "    print(f\"  RMSE:      ${test_rmse:,.2f}\")\n",
    "    print(f\"  MAE:       ${test_mae:,.2f}\")\n",
    "    print(f\"  Time:      {train_time:.2f}s\")\n",
    "\n",
    "# DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values('R¬≤ Score', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"SUMMARY TABLE\")\n",
    "print(\"=\" * 70)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# PART 8: VISUALISASI\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Loss Convergence\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "for name, (_, _, losses, _) in optimizers.items():\n",
    "    plt.plot(losses, label=name, linewidth=2)\n",
    "\n",
    "plt.title(\"Loss Convergence Comparison\", fontsize=14, fontweight='bold')\n",
    "plt.xlabel(\"Epoch\", fontsize=12)\n",
    "plt.ylabel(\"Training Loss (MSE)\", fontsize=12)\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.yscale('log')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üìà Grafik menunjukkan seberapa cepat loss turun\")\n",
    "print(\"   Semakin cepat turun = semakin bagus!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. R¬≤ Score Comparison\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c']\n",
    "bars = plt.bar(results_df['Optimizer'], results_df['R¬≤ Score'], \n",
    "               color=colors, edgecolor='black', linewidth=1.5)\n",
    "\n",
    "plt.ylabel(\"R¬≤ Score\", fontsize=12)\n",
    "plt.title(\"Test Set Performance (R¬≤ Score)\", fontsize=14, fontweight='bold')\n",
    "plt.ylim([0, 1])\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{height:.4f}', ha='center', va='bottom', fontsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üìä R¬≤ Score: Semakin tinggi semakin bagus (max = 1.0)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Prediction vs Actual (Best Model)\n",
    "best_name = results_df.iloc[0]['Optimizer']\n",
    "w_best, b_best, _, _ = optimizers[best_name]\n",
    "y_pred_best = predict(X_test, w_best, b_best)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(y_test, y_pred_best, alpha=0.6, s=50, edgecolors='black', linewidth=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], \n",
    "         'r--', lw=2, label='Perfect Prediction')\n",
    "\n",
    "plt.xlabel(\"Actual Price ($)\", fontsize=12)\n",
    "plt.ylabel(\"Predicted Price ($)\", fontsize=12)\n",
    "plt.title(f\"Prediction vs Actual ({best_name})\", fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üìç Titik yang dekat dengan garis merah = prediksi bagus\")\n",
    "print(\"   Titik yang jauh = prediksi meleset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Error Distribution\n",
    "errors = (y_test - y_pred_best).flatten()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(errors, bins=30, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "plt.axvline(x=0, color='red', linestyle='--', linewidth=2, label='Zero Error')\n",
    "\n",
    "plt.xlabel(\"Prediction Error ($)\", fontsize=12)\n",
    "plt.ylabel(\"Frequency\", fontsize=12)\n",
    "plt.title(\"Error Distribution\", fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Statistics\n",
    "mean_error = np.mean(errors)\n",
    "std_error = np.std(errors)\n",
    "plt.text(0.05, 0.95, f'Mean: ${mean_error:,.2f}\\nStd: ${std_error:,.2f}',\n",
    "         transform=plt.gca().transAxes, verticalalignment='top',\n",
    "         bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5),\n",
    "         fontsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üìä Distribusi error: Idealnya centered di 0\")\n",
    "print(f\"   Mean error: ${mean_error:,.2f}\")\n",
    "print(f\"   Std error:  ${std_error:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# PART 9: KESIMPULAN & REKOMENDASI\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = results_df.iloc[0]\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"üèÜ BEST OPTIMIZER\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nOptimizer: {best['Optimizer']}\")\n",
    "print(f\"\\nPerformance:\")\n",
    "print(f\"  ‚Ä¢ R¬≤ Score:  {best['R¬≤ Score']:.4f}\")\n",
    "print(f\"  ‚Ä¢ Test RMSE: ${best['Test RMSE']:,.2f}\")\n",
    "print(f\"  ‚Ä¢ Test MAE:  ${best['Test MAE']:,.2f}\")\n",
    "print(f\"  ‚Ä¢ Time:      {best['Time (s)']:.2f}s\")\n",
    "\n",
    "print(f\"\\nüìä INTERPRETASI:\")\n",
    "print(f\"  R¬≤ = {best['R¬≤ Score']:.4f} artinya model dapat menjelaskan\")\n",
    "print(f\"  {best['R¬≤ Score']*100:.2f}% variance dalam harga mobil.\")\n",
    "print(f\"\\n  RMSE = ${best['Test RMSE']:,.2f} artinya rata-rata error\")\n",
    "print(f\"  prediksi adalah sekitar ${best['Test RMSE']:,.2f}.\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üéì REKOMENDASI BELAJAR\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\"\"\n",
    "1. PAHAMI MATEMATIKA:\n",
    "   ‚úì Linear Algebra (matrix, dot product)\n",
    "   ‚úì Calculus (derivatives, gradients)\n",
    "   ‚úì Statistics (mean, variance)\n",
    "   ‚úì Optimization (gradient descent)\n",
    "\n",
    "2. MASTER OPTIMIZER:\n",
    "   ‚Ä¢ Mulai dengan Gradient Descent (paling simple)\n",
    "   ‚Ä¢ Pahami Momentum (lebih cepat)\n",
    "   ‚Ä¢ Gunakan Adam untuk production (paling reliable)\n",
    "\n",
    "3. BEST PRACTICES:\n",
    "   ‚úì Selalu split data (train/test)\n",
    "   ‚úì Standardize features\n",
    "   ‚úì Monitor multiple metrics\n",
    "   ‚úì Visualize results\n",
    "\n",
    "4. NEXT STEPS:\n",
    "   ‚Ä¢ Pelajari Neural Networks\n",
    "   ‚Ä¢ Explore PyTorch / TensorFlow\n",
    "   ‚Ä¢ Build portfolio projects\n",
    "   ‚Ä¢ Kaggle competitions\n",
    "\n",
    "5. RESOURCES:\n",
    "   ‚Ä¢ Andrew Ng - Machine Learning (Coursera)\n",
    "   ‚Ä¢ Fast.ai - Practical Deep Learning\n",
    "   ‚Ä¢ Papers with Code\n",
    "   ‚Ä¢ Kaggle Learn\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"‚úÖ TUTORIAL SELESAI! HAPPY LEARNING! üöÄ\")\n",
    "print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
